# .github/workflows/terraform-deploy.yml

name: Deploy Terraform

on:
  workflow_call:
    inputs:
      environment:
        description: "Environment to deploy"
        required: true
        type: string
      aws_region:
        description: "AWS Region"
        required: false
        type: string
        default: "us-east-1"
      terraform_version:
        description: "Terraform version to use"
        required: false
        type: string
        default: "1.14.3"
      working_directory:
        description: "Working directory for Terraform"
        required: false
        type: string
        default: "./src/terraform"
      tf_var_runpod_max_concurrency:
        description: "Max concurrency for RunPod upscaler"
        required: false
        type: number
        default: 5
      tf_var_ecs_max_concurrency:
        description: "Max concurrency for ECS tasks"
        required: false
        type: number
        default: 4
      tf_var_use_s5cmd:
        description: "Use s5cmd for faster S3 downloads"
        required: false
        type: boolean
        default: false
      tf_var_model_s3_bucket:
        description: "S3 bucket name containing model files"
        required: false
        type: string
        default: ""
    outputs:
      ecr_splitter_repository_name:
        description: "ECR Repository Name for Splitter Repository"
        value: ${{ jobs.apply-dev.outputs.ecr_splitter_repository_name }}
      ecr_combiner_repository_name:
        description: "ECR Repository Name for Combiner Repository"
        value: ${{ jobs.apply-dev.outputs.ecr_combiner_repository_name }}
      batch_split_job_definition_name:
        description: "AWS Batch Job Definition Name for Splitter Job"
        value: ${{ jobs.apply-dev.outputs.batch_split_job_definition_name }}
      batch_combine_job_definition_name:
        description: "AWS Batch Job Definition Name for Combiner Job"
        value: ${{ jobs.apply-dev.outputs.batch_combine_job_definition_name }}

# Best Practice: Set default permissions to read-only for security
permissions:
  contents: read
  pull-requests: write
  id-token: write # Required for OIDC authentication with AWS

jobs:
  # ============================================================================
  # Validate
  # ============================================================================
  validate:
    name: Validate & Lint
    runs-on: ubuntu-latest
    outputs:
      terraform_version: ${{ inputs.terraform_version }}
      working_directory: ${{ inputs.working_directory }}
    defaults:
      run:
        working-directory: ${{ inputs.working_directory }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ inputs.terraform_version }}

      - name: Terraform Format Check
        id: fmt
        run: terraform fmt -check -recursive
        continue-on-error: true

      - name: Terraform Init
        id: init
        run: terraform init -backend=false

      - name: Terraform Validate
        id: validate
        run: terraform validate -no-color

      - name: Comment PR with validation results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const output = `#### Terraform Format and Style üñå\`${{ steps.fmt.outcome }}\`
            #### Terraform Initialization ‚öôÔ∏è\`${{ steps.init.outcome }}\`
            #### Terraform Validation ü§ñ\`${{ steps.validate.outcome }}\`
            
            <details><summary>Validation Output</summary>
            
            \`\`\`
            ${{ steps.validate.outputs.stdout }}
            \`\`\`
            
            </details>
            
            *Pushed by: @${{ github.actor }}, Action: \`${{ github.event_name }}\`*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: output
            })

  # ============================================================================
  # Plan
  # ============================================================================
  plan-dev:
    name: Plan (dev)
    needs: validate
    runs-on: ubuntu-latest
    environment:
      name: dev
    defaults:
      run:
        working-directory: ${{ inputs.working_directory }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ inputs.terraform_version }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ vars.AWS_REGION }}
          role-session-name: GitHubActions-Terraform-Dev

      - name: Create Lambda builds directory
        run: mkdir -p lambda_builds
        working-directory: ${{ inputs.working_directory }}

      - name: Create backend config
        env:
          TF_STATE_BUCKET: ${{ secrets.TF_STATE_BUCKET }}
          AWS_REGION: ${{ vars.AWS_REGION }}
        run: |
          printf 'bucket="%s"\n' "${{ env.TF_STATE_BUCKET }}" >> backend-config.tfvars
          printf 'key="%s"\n' "dev/terraform.tfstate" >> backend-config.tfvars
          printf 'region="%s"\n' "${{ env.AWS_REGION }}" >> backend-config.tfvars
          echo "use_lockfile = true" >> backend-config.tfvars
          cat backend-config.tfvars
        shell: bash

      - name: Create terraform.tfvars
        env:
            RUNPOD_API_KEY: ${{ secrets.RUNPOD_API_KEY }}
            DIT_MODEL_S3_URI: ${{ secrets.DIT_MODEL_S3_URI }}
            VAE_MODEL_S3_URI: ${{ secrets.VAE_MODEL_S3_URI }}
            RUNPOD_MAX_CONCURRENCY: ${{ inputs.tf_var_runpod_max_concurrency }}
            ECS_MAX_CONCURRENCY: ${{ inputs.tf_var_ecs_max_concurrency }}
            MODEL_S3_BUCKET: ${{ inputs.tf_var_model_s3_bucket }}
        run: |
          cat > terraform.tfvars << EOF
          region       = "${{ vars.AWS_REGION }}"
          environment  = "dev"
          project_name = "${{ vars.PROJECT_NAME || 'upscaler' }}"
          runpod_api_key = "${{ env.RUNPOD_API_KEY }}"
          dit_model_s3_uri = "${{ env.DIT_MODEL_S3_URI }}"
          vae_model_s3_uri = "${{ env.VAE_MODEL_S3_URI }}"
          use_s5cmd = ${{ inputs.tf_var_use_s5cmd }}
          runpod_max_concurrency = ${{ env.RUNPOD_MAX_CONCURRENCY }}
          ecs_max_concurrency = ${{ env.ECS_MAX_CONCURRENCY }}
          model_s3_bucket = "${{ env.MODEL_S3_BUCKET }}"
          EOF

      - name: Terraform Init
        run: terraform init -backend-config=backend-config.tfvars

      - name: Terraform Plan
        id: plan
        run: terraform plan -no-color -out=tfplan-dev
        continue-on-error: true

      - name: Upload plan artifact
        uses: actions/upload-artifact@v4
        if: steps.plan.outcome == 'success'
        with:
          name: tfplan-dev
          path: ${{ inputs.working_directory }}/tfplan-dev
          retention-days: 5

      - name: Upload Lambda builds artifact
        uses: actions/upload-artifact@v4
        if: steps.plan.outcome == 'success'
        with:
          name: lambda-builds-dev
          path: ${{ inputs.working_directory }}/lambda_builds
          retention-days: 1

      - name: Comment PR with plan
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const planOutput = fs.readFileSync('${{ inputs.working_directory }}/plan-output.txt', 'utf8');
            const truncatedPlan = planOutput.length > 65000 ? planOutput.substring(0, 65000) + '\n\n... (truncated)' : planOutput;
            
            const output = `#### Terraform Plan üìñ - Environment: \`dev\`
            
            <details><summary>Show Plan</summary>
            
            \`\`\`terraform
            ${truncatedPlan}
            \`\`\`
            
            </details>
            
            *Pushed by: @${{ github.actor }}, Action: \`${{ github.event_name }}\`*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: output
            })

      - name: Fail if plan failed
        if: steps.plan.outcome == 'failure'
        run: exit 1

  # ============================================================================
  # Apply
  # ============================================================================
  apply-dev:
    name: Apply to Dev
    needs: plan-dev
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    runs-on: ubuntu-latest
    outputs:
      aws_region: ${{ inputs.aws_region }}
      ecr_splitter_repository_name: ${{ steps.export-terraform-outputs.outputs.ecr_splitter_repository_name }}
      ecr_combiner_repository_name: ${{ steps.export-terraform-outputs.outputs.ecr_combiner_repository_name }}
      batch_split_job_definition_name: ${{ steps.export-terraform-outputs.outputs.batch_split_job_definition_name }}
      batch_combine_job_definition_name: ${{ steps.export-terraform-outputs.outputs.batch_combine_job_definition_name }}
    environment:
      name: dev
    
    defaults:
      run:
        working-directory: ${{ inputs.working_directory }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ inputs.terraform_version }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ vars.AWS_REGION }}
          role-session-name: GitHubActions-Terraform-Dev

      - name: Create Lambda builds directory
        run: mkdir -p lambda_builds
        working-directory: ${{ inputs.working_directory }}

      - name: Create backend config
        env:
          TF_STATE_BUCKET: ${{ secrets.TF_STATE_BUCKET }}
          AWS_REGION: ${{ vars.AWS_REGION }}
        run: |
          printf 'bucket="%s"\n' "${{ env.TF_STATE_BUCKET }}" >> backend-config.tfvars
          printf 'key="%s"\n' "dev/terraform.tfstate" >> backend-config.tfvars
          printf 'region="%s"\n' "${{ env.AWS_REGION }}" >> backend-config.tfvars
          echo "use_lockfile = true" >> backend-config.tfvars
          cat backend-config.tfvars
        shell: bash

      - name: Create terraform.tfvars
        env:
            RUNPOD_API_KEY: ${{ secrets.RUNPOD_API_KEY }}
            DIT_MODEL_S3_URI: ${{ secrets.DIT_MODEL_S3_URI }}
            VAE_MODEL_S3_URI: ${{ secrets.VAE_MODEL_S3_URI }}
            RUNPOD_MAX_CONCURRENCY: ${{ inputs.tf_var_runpod_max_concurrency }}
            ECS_MAX_CONCURRENCY: ${{ inputs.tf_var_ecs_max_concurrency }}
            MODEL_S3_BUCKET: ${{ inputs.tf_var_model_s3_bucket }}
        run: |
          cat > terraform.tfvars << EOF
          region       = "${{ vars.AWS_REGION }}"
          environment  = "dev"
          project_name = "${{ vars.PROJECT_NAME || 'upscaler' }}"
          runpod_api_key = "${{ env.RUNPOD_API_KEY }}"
          dit_model_s3_uri = "${{ env.DIT_MODEL_S3_URI }}"
          vae_model_s3_uri = "${{ env.VAE_MODEL_S3_URI }}"
          use_s5cmd = ${{ inputs.tf_var_use_s5cmd }}
          runpod_max_concurrency = ${{ env.RUNPOD_MAX_CONCURRENCY }}
          ecs_max_concurrency = ${{ env.ECS_MAX_CONCURRENCY }}
          model_s3_bucket = "${{ env.MODEL_S3_BUCKET }}"
          EOF

      - name: Terraform Init
        run: terraform init -backend-config=backend-config.tfvars

      - name: Download plan artifact
        uses: actions/download-artifact@v4
        with:
          name: tfplan-dev
          path: ${{ inputs.working_directory }}

      - name: Download Lambda builds artifact
        uses: actions/download-artifact@v4
        with:
          name: lambda-builds-dev
          path: ${{ inputs.working_directory }}/lambda_builds

      - name: Terraform Apply
        id: apply
        run: terraform apply -auto-approve tfplan-dev

      - name: Terraform Output
        id: output
        run: terraform output -json > terraform-outputs.json

      - name: Upload outputs
        uses: actions/upload-artifact@v4
        if: steps.apply.outcome == 'success'
        with:
          name: terraform-outputs-dev
          path: ${{ inputs.working_directory }}/terraform-outputs.json
          retention-days: 1
      
      # Export outputs for use in other jobs/workflows
      # Sensitive outputs are skipped
      # Simple: ${{ steps.export-terraform-outputs.outputs.aws_region }}
      # Array: ${{ fromJson(steps.export-terraform-outputs.outputs.some_array_output) }}
      # Lookup: ${{ fromJSON(steps.export-terraform-outputs.outputs.vpc_intra_subnets)[0] }} to get first subnet
      - name: Export all Terraform outputs as step outputs
        id: export-terraform-outputs
        run: |
          for key in $(jq -r 'keys[]' terraform-outputs.json); do
            is_sensitive=$(jq -r --arg k "$key" '.[$k].sensitive' terraform-outputs.json)
            if [ "$is_sensitive" = "true" ]; then
              continue
            fi
            
            # Check value type - use raw (-r) for simple types, compact (-c) for arrays/objects
            value_type=$(jq -r --arg k "$key" '.[$k].value | type' terraform-outputs.json)
            if [ "$value_type" = "array" ] || [ "$value_type" = "object" ]; then
              value=$(jq -c --arg k "$key" '.[$k].value' terraform-outputs.json)
            else
              value=$(jq -r --arg k "$key" '.[$k].value' terraform-outputs.json)
            fi
            
            safe_key=$(echo "$key" | tr -c 'A-Za-z0-9_' '_' | sed 's/_*$//')
            echo "$safe_key=$value" >> $GITHUB_OUTPUT
          done
          cat "$GITHUB_OUTPUT"

  